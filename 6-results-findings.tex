%!TEX root = main.tex

% \section{Evaluation of predicting the role of trolls}
\section{Evaluation of role prediction}
\label{sec:results-findings}
In this section, we measure the classification performance of our proposed method on the Russian troll dataset.
% \autoref{subsec:experimental-settings} details the setting of the prediction task, and \autoref{sec:result-section} details the obtained results.

% \subsection{Experimental settings}
% \label{subsec:experimental-settings}

\paragraph{Experimental settings.}

\begin{table}[t!]
\centering
\begin{tabular}{c|r|r|r}
     & Train & Validation & Test \\ \hline\hline
    Left troll & 99 & 53 & 79 \\ \hline
    Right troll & 188 & 106 & 155 \\ \hline
    News feed & 20 & 11 & 22
\end{tabular}
\caption{Number of accounts for each category used for training, validation, and testing. 50 tweets are sampled for each account in the classification experiments.}
\label{tab:dataset}
\end{table}

We use a subset of the Russian troll dataset consisting of users labelled as right trolls, left trolls and news feed, as described in \autoref{sec:troll-dataset}. 
We split the accounts into 50\% train, 20\% validation, and 30\% test datasets. 
The detail statistics of each dataset is described in \autoref{tab:dataset}. 
%On average, 2,370 tweets are written by each account. 
For each account, we randomly sample 50 tweets for ease of computation. 
%Although we do not report here, we observe that the classification performances increase as we increase the number of samples regardless of methods.
We tokenise the text of tweets using a tweet pre-processing toolkit\footnote{Available at https://github.com/s/preprocessor} and remove infrequent words which occur less than 3 times in the corpus.
The co-occurrence matrix used to compute the word similarity is constructed from the entire dataset. 
%Note that although we have constructed this matrix from the troll dataset, it can also be constructed from a general corpus to capture the common similarity patterns between different words.

We test the proposed KNN approach with three distance measure (i.e. cosine distance\footnote{The bag-of-words is used to map a sequence to vector}, ED and SED), and their time-sensitive counterparts as defined in \autoref{eqn:tsknn} (denoted as t-Cosine, t-ED and t-SED, respectively). 
% We test five distant metrics without temporal information, cosine distance\footnote{The bag-of-words is used to map a sequence to vector}, ED, SED, and three distance metrics, cosine distance with temporal information, ED, and SED, where the distance is multiplied by the exponential term as described in \autoref{eqn:tsknn}. 
% We denote the three metrics use temporal information as t-Cosine, t-ED and t-SED, respectively. 
Note that the SED ranges from zero to the maximum length of sentences, therefore SED depends on the lengths of sequences; short sentences are likely to have small SED. 
To investigate the effect of sequence length, we additionally propose and test two normalised SEDs: SED/Max\footnote{Length normalisation: $\sed(\boldsymbol{a},\boldsymbol{b})/\max(\boldsymbol{|a|},\boldsymbol{|b|})$} and SED/ED\footnote{Ratio normalisation: $\sed(\boldsymbol{a},\boldsymbol{b})/\ed(\boldsymbol{a},\boldsymbol{b})$}.
As a baseline, we also test a logistic regression classifier
%, training based model, 
with and without temporal information (denoted as LR and t-LR). 
We train the LR models with bag-of-words features to classify the label of an individual tweet and predict account label based on majority vote. 
To add temporal information into the logistic regression, we compute the normalised timestamp of tweets and we add it into the feature set.
Finally, the classification performance is measured by macro and micro F1. 
Note that the dataset shows highly skewed distribution toward the right troll accounts. 
\autoref{tab:test_perf} summarises all the tested approaches and their performances.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/knn_valid_perf_lrn_3_50.pdf}
    \caption{Macro and micro F1 scores on validation set with KNN. Cosine, ED, and SED performs the best when k is 1. t-SED shows relatively consistent performances over varying numbers of neighbours.}
    \label{fig:valid_perf}
\end{figure}

\begin{table}[t!]
    \centering
    \begin{tabular}{l|l|r|r||r|r}
    \multicolumn{2}{c}{}& \multicolumn{2}{c||}{Micro F1} &  \multicolumn{2}{c}{Macro F1} \\ \hline
    &Method & K & F1 & K & F1\\ \hline\hline
    \multirow{3}{*}{Baseline}&LR & - & 0.75 &- &0.55\\
    & ED & 1 &0.72 & 1 & 0.46\\
    &Cosine & 1 & 0.75 & 1 & 0.54 \\\hline
    \multirow{3}{*}{Semantic}&SED	&1	&0.78&1	&0.62\\
    &SED/Max &1	&0.65&1	&0.35\\
    &SED/ED	& 8 &0.62&8	&0.29\\\hline
    \multirow{4}{*}{Temporal}&t-LR	& - & 0.79& -& 0.61\\
    &t-ED	& 1 & 0.83& 1& \textbf{0.75}\\
    &t-Cosine	&3	&0.81&1	&0.61\\
    &t-SED & 5 & \textbf{0.84} & 7 & \textbf{0.75}
    \end{tabular}
    \caption{Micro and macro F1 scores on test set along with the number of neighbours (K) for KNN. Although SED outperforms all baseline models, t-SED significantly outperform their non time-sensitive counterparts implying the importance of incorporating the temporal dimension.}
    \label{tab:test_perf}
\end{table}

\paragraph{Results.}
\label{sec:result-section}

\autoref{fig:valid_perf} shows the classification performances of different metrics on the validation dataset with varying number of neighbourhood size in KNN. Note that t-SED has additional parameter $\theta$, which controls the exponential rate. We perform a grid search on $\theta$ to find the best configuration and report the best validation performance in \autoref{fig:valid_perf}. One interesting pattern from the validation set is that all other metrics except time sensitive metrics suffer from having a large number of neighbours, whereas the time sensitive metrics retain stable performances across the different number of neighbours.
We conjecture that including more neighbours include more tweets from different time ranges, as done with the non time-sensitive metrics, eventually hurts the classification of individual tweets.

The results shown in \autoref{tab:test_perf} are the best performances of each approach over the range of $k$ on the validation set.
% Based on the best parameter configuration obtained from the validation set, \autoref{tab:test_perf} shows the final performance of each method on the test dataset.
Overall, the t-SED outperforms all other metrics for both macro and micro F1 scores. 
%We can understand the results by dividing it into three perspectives: 1) importance of the new cost function based on word similarity by comparing the performance between ED and SED, 2) importance of preserving order between tokens in tweets along with semantic similarity by comparing the performance between Cosine and SED, 3) importance of including temporal information by comparing the performance between the metrics with temporal information and those non-temporal counterparts.
We interpret the results from four perspectives: 
\textbf{1) The importance of word similarity} by comparing ED and SED.
% shows the importance of accounting word similarity. 
By adding the word similarity into the cost function, SED can significantly outperform ED in the role prediction.
\textbf{2) The importance of preserving order between tokens in tweets.} 
Although the naive ED performs worse than the cosine distance, SED outperforms cosine
% along with word similarity, the improvement of SED against the cosine distance 
outlines the importance of preserving order between tokens, alongside with accounting for word similarity.
%which can potentially represent more complex concepts than individual words.
\textbf{3) The importance of accounting for temporal information.} 
All time-sensitive measures outperform their non-temporal counterparts (e.g. t-LR vs. LR, or t-SED vs. SED). 
This result implies significant amounts of concept drifting in the dataset. 
We also note that t-ED and t-SED have similar performances, despite the performance difference between ED and SED.
This seems to suggest that the temporal information is more important for the successful classification than the word similarity. 
However, the best value for $k$ obtained on the validation set shows that t-SED can use a larger number of neighbours than t-ED, which implies the potential robustness of t-SED against t-ED by accounting wider context through the word similarity.
\textbf{4) Circumvention of trainable models.} 
Given the most accessible features, the trace of text, t-SED outperforms training based models (i.e. LR and t-LR). 
This implies that distance-based methods can outperform training models in the most restricted scenario where only the authored text is available (without user attributes). 
It is also important to note that the distance-based methods do not need to be retrained, whereas the training based models, such as the logistic regression, require periodical retraining to model temporal changes in a corpus.

Note that the two normalised metrics, SED/Max and SED/ED, do not help increase the performance. We conjecture that a normalisation is unnecessary due to the limited number of characters can be written at a time\footnote{Twitter has a 140-character limitation before Nov. 2017}.

%\TODO{MAR}{Not sure if this paragraph is complete, but it currently does not talk about (1) how is time included in t-Logistic and t-Cosine (this is in the prev experimental settings) and (2) does not interpret the results -- which component is the most important and why?}

\section{Results and findings: the strategy of trolls}
\label{sec:visualisation}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/anno-sed-sep-2016.png}
    \caption{[SED] September, 2016}
    \label{fig:sed-sep2016}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/sed-apr-2017.png}
    \caption{[SED] April, 2017}
    \label{fig:sed-apr2017}
    \end{subfigure}

    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/anno-tsed-sep-2016.png}
    \caption{[t-SED] September, 2016}
    \label{fig:tsed-sep2016}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/anno-tsed-apr-2017.png}
    \caption{[t-SED] April, 2017}
    \label{fig:tsed-apr2017}
    \end{subfigure}
    \caption{
        Tweets from two different time ranges (left vs right column) are embedded into two-dimensional spaces, via t-SNE, with two variants of edit distances (SED for the top row, and t-SED for the bottom row). 
        The locations are computed using the distances between pairwise distances between all tweets from the two time ranges -- i.e. one space for SED and one for t-SED.
        We plot the tweets separately based on the period they were written. 
        For SED, there is a relatively clear distinction between the different categories before the election, but they are relatively indistinguishable after the election. 
        For t-SED, the gap between 2016 and 2017 is wider than for SED since the distance between tweets increases exponentially with their time difference.
    }
    \label{fig:embedding}
\end{figure*}

To understand the behaviour and the strategy of trolls over time, we visualise the tweets using t-SNE~\cite{maaten2008visualizing}, a technique originally designed to visualise high-dimensional data through their pairwise distances. 
\autoref{fig:embedding} shows the visualisation of tweets from two different time ranges using SED and t-SED. 
Each dot in the figure represents a single tweet embedded into a two dimensional space constructed by t-SNE. 
To emphasise different behaviour of trolls over time, we plot tweets from two different time ranges: one before the presidential election (September 2016) in \autoref{fig:sed-sep2016} and \autoref{fig:tsed-sep2016}, 
and another after the election (April 2017) in \autoref{fig:sed-apr2017} and \autoref{fig:tsed-apr2017}.

\subsection{Re-examination of Russian trolls}

\textbf{Together they troll.}
Although the Clemson University researchers argued that ``with the exception of the fearmonger category, handles were consist and did not switch between categories'' \citep[p. 6]{boatwrighttroll}, the data-driven visualisation presented in \autoref{fig:embedding} reveals a somewhat different picture. 
% The position of the tweets suggests that \verify{the contents generated by trolls are not mutually exclusive to each other, and they may share some common thematic context.} \TODO{MAR}{a bit unclear!}
A cursory examination of the visualisation shows several instances where the positioning of tweets from both right trolls and left trolls overlap, suggesting that they tweet about similar or related topics. 
Similarly, \autoref{fig:sed-sep2016} and \autoref{fig:tsed-sep2016} reveal sub-clusters of news feed trolls that are positioned within the predominantly right troll cluster. 
Therefore, we cannot observe a clear separation in authored tweets based their categories through the distance metrics.
Nonetheless, many tweets are locally clustered in line with their categories, which ultimately helps us to correctly classify their type, as shown in \autoref{sec:result-section}.

\textbf{Right vs. left strategy.}
A notable pattern from \autoref{fig:embedding} is that the tweets authored by the left trolls are spread across all regions whereas those of the right trolls are more focused and relatively well clustered. 
As discussed previously, we know that generally the right trolls were focused on supporting Trump and criticising mainstream Republicanism and moderate Republican politicians. 
Compared to left trolls, right trolls have a more singular or homogeneous identity, and employ common hashtags used by similar real Twitter users, including \#tcot, \#ccot, and \#RedNationRising \citep[p. 7]{boatwrighttroll}. 
On the other hand, left trolls have a more complex discursive strategy. 
As \citep{boatwrighttroll} argue, these trolls send socially liberal messages, with an overwhelming focus on cultural identity. 
Accordingly, the position of the left trolls on the visualisation provides a stark picture of their complementary and supporting role in driving the IRA's agenda building campaign on Twitter. 
Left trolls are literally surrounding the conversation on all sides. 
In some areas they are attacking Hillary Clinton and mainstream Democratic politicians, in others they are mimicking activists from the Black Lives Matter movement, and in others discussing religious identity and Christian moralism. 
Left troll tweets are certainly distinguishable on the visualisation in terms of their position, but we can see how they play into, and strategically function alongside, the news feed and right trolls. 
To examine these observations in more detail we can zoom in to specific regions of interest within the visualisation to analyse the tweet content.

\subsection{Left and right trolls worked together}

\textbf{Leveraging racial politics.}
Most of the tweets from the notable right troll cluster in \autoref{fig:sed-sep2016} and \autoref{fig:tsed-sep2016} (\textbf{tag A} in the figures) contain the hashtag \#ThingsMoreTrustedThanHillary, which shows the strategic behaviour of certain right trolls to make the Democratic candidate distrustful. 
This strategy is also part of the over-arching agenda of the left trolls, who not only undermined the trust in Hillary Clinton, but co-opted the Black Lives Matter movement and related topics to negatively impact her campaign. 
As \citep[p. 8]{boatwrighttroll} show, left trolls authored tweets such as ``NO LIVES MATTER TO HILLARY CLINTON. ONLY VOTES MATTER TO HILLARY CLINTON'' (@Blacktivists, October 31, 2016). 
Furthermore, the central cluster of right trolls (\textbf{tag B}) in \autoref{fig:tsed-sep2016} contains tweets that show the support of Trump from black people, in addition to tweets from typical Trump supporters. 
The following are example tweets from this cluster of right trolls:
\begin{itemize}
    \item {\small ``Join Black Americans For Trump, ``Trump is the best choice for ALL Americans!'' Join Today at https://t.co/NJBoTamxDi  \#Blacks4Trump'' (@marissaimstrong)};
    \item {\small ``Why I Support Donald Trump https://t.co/U0oT8odMOB  \#BlacksForTrump \#Blacks4Trump \#BlackLivesMatter \#ImWithHer \#DemExit \#MAGA'' (@hyddrox)}.
\end{itemize}
We therefore observe a complex interplay between left and right trolls, whereby both attempt to co-opt and strategically utilise racial politics and ethnic identity \citep{phinney2000ethnic},
%% MAR: soothing a bit the message
%to advance the end-goals of the IRA, 
even though they use different approaches. 
This resonates with and provides new insights on recent analysis of Russian troll communication on Twitter, where trolls were found to make a ``calculated entry into domestic issues with the intent to polarise and destabilize'' \citep[p. 4]{stewart2018examining}.

\textbf{Utilising religious beliefs.}
From the central part of \autoref{fig:tsed-apr2017}, we observe tweets from both ideologies and we find a cluster of conversations (\textbf{tag C}) related to personal religious beliefs, such as:
\begin{itemize}
    \item {\small ``Just wait \& \#God will make things great'' (@acejinev)};
    \item {\small ``Each of us is a Masterpiece of Godâ€™s Creation. Respect Life! \#Prolife'' (@j0hnlarsen)}.
\end{itemize}
Although the hashtags used in these religious tweets are often different for the left and right trolls, their similarity is captured by the metric.
This reveals an interesting strategy whereby trolls from both left and right pretend to be ordinary American citizens who, although ideologically different, are united by shared religious beliefs. 
This indicates that not all trolls in a category acted unitarily, and the tweets they emitted cluster into groups corresponding to their different sub-roles and strategies.
Using the proposed t-SED measure and visualisation, one can zoom in and gain richer insights into the strategies and identities of these user accounts (down to individual actions).
% \verify{This emphasises the important \textit{intra-group} differences of Russian trolls that our t-SED similarity measure brings to light: when we zoom in and we explore particular clusters and regions, we gain richer insights into the strategies and identities of these user accounts (down to individual actions), while also being able to classify them accurately into their higher-level categories.}

\subsection{The multiple agendas of news feed trolls}
When studying news feed trolls, we observe how different clusters promote specific themes of news articles. 
The slender cluster of news feed trolls (\textbf{tag D}) in \autoref{fig:tsed-sep2016} often contain the hashtag \#news, and report incidences of violence and civil unrest. For example, tweets from this cluster include:
\begin{itemize}
    \item {\small ``Warplanes hit Aleppo in heaviest attack in months, defy U.S.  \#news'' (@specialaffair)};
    \item {\small ``Pedestrian hit, killed by train in Mansfield https://t.co/kvmFEgf8Ps \#news https://t.co/TXsol3YjgA'' (@todaybostonma)}; 
    \item {\small ``One person killed during violent Charlotte protest; officer hurt https://t.co/IYyg0xmf0L https://t.co/UbzzAeW3zR'' (@baltimore0nline)}.
\end{itemize}
On the other hand, the small left-most cluster of news feed trolls (\textbf{tag E}) in \autoref{fig:tsed-sep2016} focus on the hashtag \#politics, and have a focus on federal political issues and politicians as well as policy and regulation. Tweets from this cluster include, for example:
\begin{itemize}
    \item {\small ``Obama Trade Setbacks Undercut Progress in Southeast Asian Ties  \#politics'' (@newspeakdaily)};
    \item {\small ``Is federal government trying to take down for-profit colleges?  \#politics'' (@batonrougevoice)};
    \item {\small ``Clinton takes aim at Trump supporters https://t.co/fxEox7N74Z \#politics'' (@kansasdailynews)}.
\end{itemize}
This suggests that the IRA strategy for news feed trolls comprised multiple agendas -- they are not simply a homogeneous group. We observe that the clusters help to illuminate the within-group variation for this troll category, and we might speculate that the clusters correspond to, or at least highlight, the agenda-setting strategies that news feed trolls carried out, as well as their relationship to other types of trolls (i.e., by analysing their proximities in t-SNE space).

\subsection{The shifting sands of troll identity over time}
By analysing two different time ranges, we can notice that there is less separation between the tweets belonging to the different roles
% the tweets between different categories are located more closely after the election 
(see \autoref{fig:sed-apr2017} and \autoref{fig:tsed-apr2017}). 
The clustering structure around September 2016 is comparatively clearer than the structure around April 2017. 
The difference suggests that, for some reason, the strategic behaviour of trolls changed markedly before and after the election. 
We are not aware of any previous research that has identified this, let alone that offers an explanation why.
Interestingly, one strategy that appears to continue after the elections is seeding fear: the t-SED visualisation in \autoref{fig:tsed-apr2017} reveals a cluster of news feed trolls (\textbf{tag F}) with the particular focus on reporting negative news about shootings and gun violence, crime and fatalities. 
Example tweets from this cluster include: 
\begin{itemize}
    \item {\small ``Gunman shoots woman at Topeka Dollar General https://t.co/gQgQy8B0Hh'' (@kansasdailynews)};
    \item {\small ``Police: Father accidentally shoots son while fighting off intruder https://t.co/kAD9shfp7t'' (@kansasdailynews)}; 
    \item {\small ``Police: Suspect dead after woman, child abducted in Homewood https://t.co/TcTNmc5oFu'' (@todaypittsburgh)}.
    %((d), 20.1 -15.9)
\end{itemize}
Although we do not have scope in this paper to undertake further analysis of the clustering after the election, it is obvious that t-SED (\autoref{fig:tsed-apr2017}) offers a different view of Russian troll strategies as compared to SED (\autoref{fig:sed-apr2017}).
% , which as we showed in \autoref{sec:result-section} offers improved predictive performance over existing approaches such as cosine distance and edit distance. 
Zooming out to the largest scale, we see generally that taking into account temporal information is important because it outlines the drift in topics of discussion.
% provides a new understanding of how semantic similarity varies over time, which we would otherwise miss out on using standard approaches.
