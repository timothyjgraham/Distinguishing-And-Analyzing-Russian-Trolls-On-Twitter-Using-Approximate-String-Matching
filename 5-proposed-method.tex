%!TEX root = main.tex

% \section{N-gram Modelling}
% \label{sec:ngram}

% N-gram modelling is one of the most widely used methods in natural language processing. It is a contiguous sequence of n tokens from the given text. Given a sentence, we can construct a list of n-grams from the sentence by finding sequences of words that occur next to each other. Normally, an n-gram of size 1 is referred to unigram, an n-gram of size 2 is referred to bigram, and size 3 is trigram, etc. 

% Only unigram and bigram are used in this research, as they are most commonly used, and for the purposes of this study it is enough to extract the features of texts by using unigram and bigram tokens. 

% Unigrams take one token as a feature. The main disadvantage of doing this is that we loss positional information in a unigram feature representation. While we compute the similarity of tokens, we also want to learn about the context or sentiment of using specific tokens. To address this, bigrams are used as a feature, which is using contiguous sequences of two words to construct features. For example, in the Russian Troll dataset, both Left Troll and Right Troll would highly mention ``Trump'', if we use unigram, the token ``Trump'' will be high frequency used with other tokens in both Left Troll and Right Troll tweets, However, if bigram is used, it may introduce some unique information in Left Trolls or Right Trolls.

\section{Classifying the roles of trolls}
\label{sec:sed}

In this section, we develop a new method for identifying roles of social media users.
In \autoref{subsec:operationalizing-monads}, we operationalise the theory of monadology for online social media users.
Next, in \autoref{subsec:majority-voting-KNN}, we introduce a new time-sensitive distance measure for texts and a majority voting framework for detecting roles.
Finally, in \autoref{subsec:semantic-edit-distance} we introduce a semantic version of the edit distance.

% \subsection{Social roles via similarity metrics}
%% MAR: new, sexier subtitle
\subsection{Operationalising Tarde's monadology}
\label{subsec:operationalizing-monads}

As discussed in Section \ref{sec:tardeANT}, \citet{latour2012whole} broadly suggest that we can replace the idea of social role and identity in terms of individual attributes (e.g., ideology, gender, age, location, etc), and instead define entities based on the traces they leave behind.
Here we define a trace as a succession of timestamped items (i.e. here the tweets of an author).
% This implies that two users might be similar because their traces (e.g., words and hashtags used in tweets) have a large number of items in common.
Therefore two users are similar when their traces contain a large number of similar items (e.g. the tweets have words and hashtags in common). 
% While a similarity-based approach is promising, 
While measuring similarity between items (using off-the-shelf similarity measures) is promising, it does not preserve the order in which items occur. 
However, the ordering of tweets provides crucial information to define and understand the roles that users have in the social space. 
Social roles are not static - user actions and identities change over time, and they define them differently from one epoch to another.

In line with the monadological theory \citep{latour2012whole,tarde2011monadology}, we aim to distinguish the social roles of Russian trolls via their trace data, which consists of tweets over time. 
To tackle this problem, we assume that each individual tweet can be labelled by one of the target labels. For example, in our dataset (see \autoref{sec:troll-dataset}), a tweet can be classified into one of three categories or \text{roles}: left troll, right troll, and news feed troll.
We further assume that if a tweet is written by an author whose label is already known, i.e., in a training set, then we label the tweet according to the label of the author. 
While each individual tweet may not correctly reflect the role of an account (for example, some right trolls may advocate for the other side to create more confusion from time to time), when they are aggregated it should reflect the correct role of the account (right versus left ideology, or news feed troll). 
Or from a social theory point of view, we might provocatively say that `the whole is always smaller than its parts' \citep{latour2012whole}. 
When we say `right' troll, for example, what actually underpins this ideological category is a large and complex landscape of tweets, which, if we zoom in further, contains an even larger and more complex set of words, hashtags, urls, and so on. There are not multiple `levels' of reality (e.g. micro and macro) -- instead, we have a one-level standpoint whereby actors (e.g. Russian trolls) are defined by their network (i.e. tweets, elements of tweets). As \citep[p. 593]{latour2012whole} write: ``This network is not a second level added to that of the individual, but exactly the same level differently deployed''.


%  of elements assembled differently depending how we navigate them. 

% For example, a musical song can be decomposed as a set of notes, however the order that these notes occur gives form to the song. Similarly, if the social role of `Herve C' as mentioned previously is traced via a series of web searches, it is important that `PhD from Penn University' occurred \textit{before} `professor of economics at Paris School of Management', such that the sequence of actions or events over time provides important information about this individual. Therefore, similarity metrics such as edit distance or cosine distance may not be fully sufficient to capture the social role of entities, given the importance of time for understanding social change and identity.

% As discussed in \autoref{sec:tardeANT},  As the social theory suggests,...  As a result, the similarities and differences we have with others may also look different over time.

% In this way, the theory asserts that we need to take into account the digital traces that individuals leave behind to identify who they are, and to distinguish and group them together into meaningful clusters. In this case we want to identify the different types (and sub-types, as we show later) of Russian trolls via their trace data, which consists of tweets over time. 
% Importantly, our analysis necessarily shifts the focus to the tweets themselves, which accords with the principle of `generalised symmetry' in Actor-Network Theory whereby all entities - human and non-human - should be described in the same terms \citep{Callon1986}. 

We operationalise this problem in terms of \textit{time-sensitive similarity}: tweets that share similar word/hashtag co-occurrence patterns \textit{and} were authored closely in time should be clustered closely together. 
% As discussed in Section \ref{sec:troll-dataset}, given that we have the ground truth labels for classifying Russian troll tweets by type (e.g. left troll, right troll, news feed troll, etc), we can assess the validity of these clusters by comparing them to the known labels. It follows that the social role of \textit{users} (in this case Russian trolls) can be derived as the sum of the labels of individual tweets. For example, we would expect that a right troll's identity is composed of tweets that are grouped more closely to tweets by other right trolls. 
This provides a basis to evaluate whether, and to what extent, the claims of the social theory have empirical validity and predictive power. 
Importantly, it also provides the opportunity to reevaluate the roles that Russian trolls occupied on Twitter during and after the 2016 U.S. Election, and whether we can learn new insights about their roles and strategies by anchoring our analysis to the monadological theory. 
However, first we need to devise a similarity metric that can take into account both semantic and temporal information, which we undertake in the following two subsections.

% Importantly, a similarity-based approach lends itself to visualisation and affords the ability to differentiate between tweets (and trolls) depending on the scale we wish to `zoom' in to. It might be the case that there are in fact two or more distinguishable sub-groups of news feed troll tweets, and that if we zoom in closely we are able to discover and learn more about the microcosm of news feed troll tactics and activity. Likewise, by zooming out to the aggregate scale we may wish to analyse where left troll tweets are positioned in relation to other types of tweets - are they grouped into a tight homogeneous cluster, or are the motives and actions of these trolls more heterogeneous due to their supporting role in the over-arching political goals of the IRA? This requires a shift in thinking, where we move from fixed notions of identity (e.g., attributes such as left and right) towards degrees of similarity that are fully quantifiable. The framework we devise, apply, and evaluate in the remainder of this paper directly addresses this problem. 

%In the case of Twitter data and identifying Russian troll accounts, it is easy to see that for a given `right troll' $u_i \in U$, their `monadic' identity can be described as a vector $\vec v$, which is a sequence of actions or events initiated by $u_i$, ordered by time. As a simplifying example, if we extract the hashtags that $u_i$ has used in tweets, we might find that they used \textit{\#MAGA} at time $t_0$, \textit{\#crookedhillary} at $t_1$, and \textit{\#clintonemails} at $t_2$. Thus the sequence $\vec v_i$ expressing their identity is $\left<\#MAGA, \#crookedhillary, \#clintonemails\right>$. Similarly, another right troll $u_j$ might have the following monadic identity $\vec v_j$: $\left<\#clintonemails, \#MAGA, \#trump2016\right>$, while a `left troll' $u_k$ authored the following sequence of hashtags $\vec v_k$: $\left<\#blacklivesmatter, \#bernieorbust, \#feelthebern\right>$. Although this example is purely illustrative, it is clear that the monadic identities of the right trolls, encoded as $\vec v_i$ and $\vec v_j$, are more similar compared to the left troll, encoded as $\vec v_k$. The question that we pose in this paper is whether we can exploit this approach to encoding identity in order to classify users based on similarities in their trace activity over time. In the next section we show how this is possible when we make some modifications to an approximate string matching technique known as edit distance.

%Edit distance has a wide range of applications, especially in information retrieval, natural language processing and computational biology \citep{navarro2001guided}. In terms of natural language processing, edit distance is applied to the correction of spelling mistakes or OCR (Optical Character Recognition) errors. \cite{arora2010recognition} combine neural networks and edit distance to recognize non-compound handwritten Devnagari characters and achieve a high recognition at 90.74\%. In OCR application, the edit distance is used to obtain the minimum number of the editing operations needed to transform the wrong word to the right word in the dictionary. In order to correct the wrong words, we reserve a set of solutions that require fewer editing operations. In computational biology, DNA and protein sequences can be seen as long strings over specific alphabets, which stores biological information representing the genetic code of living beings. It is fundamental and essential to search and comparing specific sequences over those strings. 
 
%Edit distance also has several limitations. In particular, it can only quantify the similarity of the structure of strings composed of symbols in an alphabet $\Sigma$, while not considering the semantic space in which the elements of $\Sigma$ occur. This is a limitation because while detecting social bots or trolls using edit distance, we want to take some contextual factors into account, in this case, the latent semantic structure of the input data (natural language expressed in tweets). For example, consider the following three sentences: ``I love music''; ``I hate music''; and ``I like music''. Every word can be considered as a symbol of some alphabet $\Sigma$, thus the edit distance between each pair of two sentences is 1. However, ``love'' is more semantically similar to ``like''. In this situation, the distance between ``I love music'' and ``I like music'' should be less than the distance between ``I love music'' and ``I hate music''. 

%It follows that if we wish to use edit distance to distinguish between the identity of Twitter users using unsupervised clustering techniques, then it is critical to take semantic similarity into account. This is the problem that we address in Section X. Before we tackle this problem, the next section provides details of the Russian Troll Dataset as well as the types of trolls that we aim to distinguish between using an unsupervised troll detection approach.

\subsection{Time-sensitive metric for trace classification}
\label{subsec:majority-voting-KNN}

% Under the assumptions where 
Given that each tweet is labelled using one target label, our goal aims to distinguish types of accounts based on their tweets.
Unlike a general supervised classification problem, where pairs of an input and label are provided as an example, our classification algorithm needs to predict a label from a set of timestamped text snippets authored by a target account. 
We formulate the user account classification as a majority voting problem, where the majority label of tweets is the predicted label of the corresponding account. 
The open question is how to classify the label of an individual tweet given a set of training traces (i.e. sequences of tweets) in terms of the time-sensitive similarity.

We employ $k$-nearest neighbour algorithm (KNN) to classify labels of tweets. 
A KNN classifies a data point based on the majority labels of $k$-nearest neighbour based on \textit{distances} to the other labelled data points.
%\TODO{DW}{I'm looking for a sentence that explains why KNN is a perfect candidate from the perspective of our operationalization, but is it necessary?} \TODO{MAR}{I don't get this!}
Let $\boldsymbol{s}_i$ and $\boldsymbol{s}_j$ be two sequences of tokens, constructed by tokenising tweets $i$ and $j$;
let $t_{i}$ and $t_{j}$ be the timestamps of tweets $i$ and $j$, respectively. 
We propose a time-sensitive distance metric between tweets $i$ and $j$ formulated as
\begin{align}
    D(i, j) = \dist(\boldsymbol{s}_i, \boldsymbol{s}_j) \times \exp(\theta |t_{i} - t_{j}|),\quad \theta>0
    \label{eqn:tsknn}
\end{align}
where $\dist(\boldsymbol{s}_i, \boldsymbol{s}_j)$ measures a distance between tokenised sequences $\boldsymbol{s}_i$ and $\boldsymbol{s}_j$ and the exponential term 
% measures the temporal difference  
penalises large timestamp differences between the two tweets.
This is required because sometimes seemingly similar text snippets may represent completely different concepts, because the meaning of the employed terms has evolved with time.
For instance, the hashtag \#MeToo had a general meaning prior to 15 October 2017, whereas afterwards the meaning of the same hashtag changed dramatically with the emergence of the \#MeToo social movement on Twitter.
By adopting the exponential penalisation inspired from point process theory~\cite{leskovec2008microscopic,rizoiu2018hawkes}, the KNN weights more towards temporally related tweets.

In general, the Euclidean distance metric is employed for the function $\dist(\boldsymbol{s}_i, \boldsymbol{s}_j)$, when $\boldsymbol{s}_i$ and $\boldsymbol{s}_j$ are defined in an Euclidean space. 
However, in our case, $\boldsymbol{s}_i$ and $\boldsymbol{s}_j$ are sequences of word tokens for which the Euclidean distance is not defined. 
One may use a bag-of-words representation of tokens to map the sequence of tokens into a vector space, and then employ a text distance metric such as cosine distance.
However, the bag-of-words representation loses the ordering of tokens, which may embed thematic concepts that cannot be understood from individual words.
In the next section, we propose a new distance metric to compute the distance between two sequences of tokens while preserving the temporal ordering between tokens. 
% \verify{
% Through experiments in \autoref{sec:results-findings}, we empirically show the importance of preserving ordering in a sequence comparison.
% }\TODO{MAR}{to check!} DW: not necessary

\subsection{Semantic edit distance}
\label{subsec:semantic-edit-distance}

We propose a new text distance metric $\dist(\cdot, \cdot)$ to capture semantic distance between two sequence of symbols based on the edit distance (ED) metric. 
The ED is a method to quantify the distance between two symbolic sequences by calculating the minimum value of the required edit operations to transform one sequence into the other. 
There may be different sets of operations according to the definition of ED. 
The most common form of ED is known as Levenshtein distance~\cite{navarro2001guided}. 
In Levenshtein's original definition, the edit operations include the insertion, deletion and substitution, and each of these operations has a unit cost. 
Therefore the original ED is equal to the minimum number of the required operations to transform one string into the other. 

Formally, given two sequences $\boldsymbol{a} = a_1, a_2, ..., a_n$ and $\boldsymbol{b} = b_1, b_2, ..., b_m$, the edit distance is the minimum cost of editing operations required to transform $\boldsymbol{a}$ into $\boldsymbol{b}$ via three operations: (i) insert a single symbol into a string; (ii) delete a single symbol from a string and (iii) replace a single symbol of a string by another single symbol, associated with non-negative weight cost $w_{\ins} (x)$, $w_{\del} (x)$ and $w_{\sub} (x,y)$, respectively. 
Let $\boldsymbol{a}$ and $\boldsymbol{b}$ be sequences of $n$ and $m$ symbols, respectively. The edit distance between $\boldsymbol{a}$ and $\boldsymbol{b}$ is given by $\ed(n,m)$, defined recursively,
\begin{align*}
  \ed(i,0) =& \sum\limits_{k=1}^i w_{\del} (a_k) \hspace{6.5em} \text{for } 1 \leq i \leq n\\
  \ed(0,j) =& \sum\limits_{k=1}^j w_{\ins} (b_k) \hspace{6.4em} \text{for } 1 \leq j \leq m
\end{align*}
\begin{align*}  
  \ed(i,j) =&
  \begin{cases}
    \ed(i-1,j-1) \hfill \text{if } a_i = b_j\\
    \min 
    \begin{cases}
        \ed(i-1,j) + w_{\del} (a_i)\\
        \ed(i,j-1) + w_{\ins} (b_j)\\
        \ed(i-1,j-1) + w_{\sub} (a_i,b_j)
    \end{cases}
    \\ \hfill \text{otherwise.}
  \end{cases}
\end{align*}
In the original ED, each operation is often assumed to have a unit cost. The unit cost assumption is convenient to measure the distances, however, it does not reflect the similarity between different symbols.
For example, given sentences $\boldsymbol{s}_1 =$ ``I like music'', $\boldsymbol{s}_2 =$ ``I love music'' and $\boldsymbol{s}_3 =$ ``I hate music'', $\ed(\boldsymbol{s}_1, \boldsymbol{s}_2) = \ed(\boldsymbol{s}_2, \boldsymbol{s}_3) = 1$ if we assume word level edit distance where each symbol corresponds to a word token in a vocabulary. However, ``love'' and ``like'' have more similar meaning than ``love'' and ``hate'' or ``like'' and ``hate''. 
In this situation, we expect that the distance between $\boldsymbol{s}_1$ and $\boldsymbol{s}_2$ should be less than the distance between $\boldsymbol{s}_2$ and $\boldsymbol{s}_3$.

As it turns out from the previous example, it is essential to understand and measure similarity between word symbols to further measure the distance between sentences.
% There is no ground truth way 
No canonical way exists to measure similarities between words, but it is often assumed that if words are used frequently in similar context, then the words play a similar role in sentences.
To capture the context of words, we compute the co-occurrence statistics between words, which shows how often a certain word is used together with the other words.
We first construct a co-occurrence matrix based on the number of times a pair of words is used in the same tweet. 
Then, to measure how frequently a pair of words are used in similar context, we compute the cosine similarity between two co-occurrence vector corresponding to the rows from the co-occurrence matrix. 
Therefore, the more two words are used frequently in a similar context provided by co-occurring words, the more similar they are based on the cosine similarity. 
From now on, we denote $\simt(x,y)$ as the cosine similarity of word $x$ and $y$ from the co-occurrence matrix.
Many previous studies have shown that the co-occurrence patterns can capture meaningful properties of words including synonymousness~\cite{mikolov2013efficient,pennington2014glove}.

We propose an edit distance endowed with novel cost functions of the three edit operations, named semantic edit distance (SED), using the word similarity.
The more similar two sentences are, the fewer the editing operation should cost. In other words, the cost of operation equals to the dissimilarity of two words. Based on this intuition, we propose three cost functions for edit operations as follows:
\begin{align} 
\label{eqn:del}
  w_{\del} (a_i) &= 1 - \simt(a_i, a_{i-1})\\
\label{eqn:ins}
  w_{\ins} (b_i) &= 1 - \simt(b_i, b_{i-1})\\
\label{eqn:sub}
  w_{\sub} (a_i,b_j) &= 1 - \simt(a_i, b_j)
\end{align}
The intuitions behind each of cost function are
\begin{itemize}
  \item For the deletion in \autoref{eqn:del} (or insertion in \autoref{eqn:ins}, resp.), if two consecutive symbols are similar, deleting (inserting) the latter one would not cost much, and the deletion (insertion) operation would have little influence on distance between two strings. 
  %\item For the insertion , if two consecutive symbols of string $b$ are similar, inserting the latter one $b_j$ would not cost much, and the insertion operation would have little influence on distance between two strings. 
  \item For the substitution in \autoref{eqn:sub}, if the symbol $a_i$ of sequence $\boldsymbol{a}$ is similar to the symbol $b_j$ of sequence $\boldsymbol{b}$, the substitution should not cost much. 
\end{itemize}
We denote $\sed(\cdot, \cdot)$ as $\ed(\cdot, \cdot)$ endowed with the above three operation costs.
Finally, applying $\sed(\cdot, \cdot)$ to $\dist(\cdot, \cdot)$ in \autoref{eqn:tsknn} results in a time-sensitive semantic edit distance, denoted as t-SED in the rest of this paper.


%Note that the distance between symbols is based on the similarity of the corresponding meaning and semantic context, instead of similarity with respect to the syntactical representation (e.g. the format and sequence of strings). The term semantic similarity is often confused with the term semantic relatedness, which is actually different. Semantic similarity is more specific than semantic relatedness and often refer to synonymous, but the latter also includes concepts such as antonymy. For example, ``love'' and ``like'' are semantic similar, ``love'' and ``hate'' are semantic related, but ``love'' and ``hate'' are not semantic similar, as they have opposite meanings.
