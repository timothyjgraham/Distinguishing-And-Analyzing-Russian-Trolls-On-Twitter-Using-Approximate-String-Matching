%!TEX root = main.tex

\section{Background}

We structure the discussion of background work into three categories: (1) related work on social media trolls and social bots; (2) a theoretical framework for measuring user `identity' using social media data; and (3) work relating to edit distance and approximate string matching.

\subsection{Political bots and trolls online}
%, applied to to the 2016 U.S. election.
\textbf{Social Bots and Trolls.} In recent years social bots and online trolls have attracted considerable scholarly attention. Recent studies have investigated the impact and influence of bots in social media \citep{aiello2012people}. Social bots have been shown to influence public opinion, spread fake news \citep{shao2017spread}, and affect the finance and stock market \citep{ferrara2016rise}. There has also been much research on general troll behaviour, slightly similar to social bots, trolls tend to provoke others and draw people into arguments and diverting attention \citep{herring2002searching}. \cite{buckels2014trolls} also indicate that there is a robust association with trolling behaviour and sadism.

\textbf{Distinguishing user identities on social media}. While social bots and trolls in social media become highly prevalent and influential, the methods to detect them in social networks has also received wide attention \citep{cook2014twitter}. Currently, the state-of-the-art method to detect social bots is the BotOrNot API \citep{davis2016botornot}. BotOrNot uses a Random Forest classifier, an ensemble supervised learning method, to measure the likelihood of a user being a bot based on more than 1000 features extracted from meta-data, patterns of activity, and tweet content \citep{varol2017online}, and can achieve a performance of 0.95 AUC (Area Under ROC Curve). Additionally, \cite{morstatter2016new} propose a bot detection model which considers recall in the formulation and achieve a better performance than the heuristics and topic modelling baseline methods. \cite{ferrara2016rise} also mention many other detection methods such as detection based on social network information and based on crowd-sourcing and leveraging human intelligence. However, all of these methods requires extensive information about each account, including their network structures. It is unclear whether the methods can take into account topical changes in the social media space. %However, all of these methods require the costly annotation of training data, and requires many attributes such as friends, followers, content and sentiment of tweet, social network patterns, and activity time series \citep{varol2017online}. 

On the other hand, automatically distinguishing trolls from regular users is a difficult problem, as there is currently no unified definition of what they are across multiple contexts online, and current approaches rely on manually annotated training data sets \citep{mihaylov2015finding} that are costly in terms of time and resources. Moreover, in addition to the general troll, there are also \textit{different types of} trolls employed by specific agencies to achieve specialised goals, such as Russian Trolls employed by the Internet Research Agency (IRA) to influence the political discourse and public sentiment in the United States \citep{boatwrighttroll}. The Clemson researchers \cite{boatwrighttroll} used advanced tracking software of social media to collect tweets from a large number of accounts that Twitter has acknowledged as being related with the IRA. The researchers first qualitatively analyse the Twitter data then use quantitative analysis to explore how behaviour changes over time.

Identifying and differentiating specific sub-groups or types of trolls poses a difficult challenge. Using qualitative methods, the Clemson University study identified five types of trolls, namely right troll, left troll, news feed, hashtag gamer, and fearmonger \citep{boatwrighttroll}. They found that each type of troll exhibited vastly different behaviour in terms of tweet content, reacted differently to external events (such as Wikipedia's leak of the hacked Podesta emails on October 7, 2016), and had different patterns of activity frequency and volume over time \citep[p.10-11]{boatwrighttroll}. Although the Russian troll handles generally behaved consistently according to their type, there were instances where handles switched categories, such as the \textit{fearmonger} trolls. Trolls of different types also worked in unison to advance the agenda of the IRA. To make sense of the troll types and to explain their role and motives with respect to the broader Russian political agenda, the Clemson researchers closely analysed the content of tweets, in particular the hashtags that were deployed, and the timing of the tweets in relation to external events that occurred during the period of analysis. For example, right troll activity had a massive spike in response to the Chelsea bombing on September 17th, 2016. 

Therefore we observe a close connection between \textit{semantics} (what trolls talk about), \textit{temporality} (when they are active and how hashtags are deployed over time), and the presupposed identity that lends them a social position and drives their behaviour (e.g. right versus left troll). Our interest in this paper is to develop and evaluate a framework that can accurately identify types of users within a population (in this case Russian troll types) by clustering them based not only on semantics but also temporality, that is, the order in which activities occur over time. However, before proceeding further it is first necessary to define and conceptualise what we mean by `identity', including how we propose to quantify and analyse it using approximate string matching techniques.

\subsection{Quantifying `identity' using online trace data}

Gabriel Tarde's ancient theory of monadology (Tarde, 2012 [1895]) has recently been adapted into the body of social theory known as Actor-Network Theory (ANT). It promises a powerful framework for the study of identity and social change in heterogeneous networks (Latour et al, 2012). In the 19th century, Tarde's ideas proved not only difficult to conceptualise but even more difficult to put into practice as an analytical approach due to a lack of available data. It is perhaps for this reason that Tarde's alternative approach to describing social processes was not empirically testable and subsequently relegated to a footnote in history.

However, Latour et al. (2012) argue that the onset of the information age and the availability of digital data sets make it possible to revisit Tardeâ€™s ideas and render them practical. By examining the digital traces left behind by actors in a network (human and non-human), Latour et al. (2012: 598) argue that we can `slowly learn about what an entity ``is'' by adding more and more items to its profile'. The radical conclusion is that datasets `allow entities to be individualized by the never-ending list of particulars that make them up' (Latour et al. 2012: 600). Hence, a monad is a `point of view, or, more exactly, a type of navigation that composes an entity through other entities' (Latour et al. 2012: 600).

As an example of this form of analysis, Latour et al. (2012) use the example of looking up an academic named `Herve C.' on the web to show how collecting information through various digital sources results in the assemblage of a network that defines an actor's identity. As the authors argue: `The set of attributes - the network - may now be grasped as an envelope - the actor - that encapsulates its content in one shorthand notation' (Latour et al. 2012: 593). Instead of atomic nodes (micro) that somehow `enter into' or `end up forming' structures (macro), we have a very different view of identity: in order to know what something is, we simply follow the traces that it leaves behind through its relations to other entities:

\begin{quote}
If for instance we look on the web for the curriculum vitae of a scholar we have never heard of before, we will stumble on a list of items that are at first vague. Let's say that we have been just told that `Herve C.' is now `professor of economics at Paris School of Management'. At the start of the search it is nothing more than a proper name. Then, we learn that he has a `PhD from Penn University', `has written on voting patterns among corporate stake holders',`has demonstrated a theorem on the irrationality of aggregation', etc. If we go on through the list of attributes, the definition will expand until paradoxically it will narrow down to a more and more particular instance. Very quickly, just as in the kid game of Q and A, we will zero in on one name and one name only, for the unique solution: `Herve C.'. Who is this actor? Answer: this network. What was at first a meaningless string of words with no content, a mere dot, now possesses a content, an interior, that is, a network summarized by one now fully specified proper name (Latour et al., 2012: 592).
\end{quote}

To summarise, what Latour et al (2012) appear to suggest is that we can replace the idea of identity in terms of individual attributes (e.g., gender, age, location, etc), and focus instead on defining entities based on the traces they leave behind. This implies that two users might be similar because the trace data they leave behind (e.g., words and hashtags used in tweets) have a large number of elements in common. However, whilst such an approach is interesting, it also has the limitation that it does not preserve the order in which events occur. For example, a musical song can be decomposed as a set of notes, however the order that these notes occur gives form to the song. Similarly, if the identity of `Herve C' as mentioned previously is traced via a series of web searches, it is important that `PhD from Penn University' occurred \textit{before} `professor of economics at Paris School of Management', such that the sequence of events provides important information about the identity of this individual unfolding over time.

In this way, the theory asserts that we need to take into account the digital traces that individuals leave behind to identify who they are, and to distinguish and group them together into meaningful clusters. In this case we want to identify the different types (and sub-types, as we show later) of Russian trolls via their trace data, which consists of tweets over time. Importantly, our analysis necessarily shifts the focus to the tweets themselves, which accords with the principle of `generalised symmetry' in Actor-Network Theory whereby all entities - human and non-human - should be described in the same terms \citep{Callon1986}. 

We conceptualise this problem in terms of similarity: tweets that share similar word/hashtag co-occurrence patterns \textit{and} were authored close in time should be clustered closely together. Given that we have the ground truth labels for classifying Russian troll tweets by type (e.g. left troll, right troll, news feed troll, etc), we can assess the validity of these clusters by comparing them to the known labels. It follows that the identity of \textit{users} can be derived as the sum of the identities of individual tweets. For example, we would expect that a right troll's identity is composed of tweets that are grouped more closely to tweets by other right trolls. This provides a basis to evaluate whether, and to what extent, the claims of the social theory have predictive power and empirical validity. 

At the same time, a similarity-based approach lends itself nicely to visualisation and affords the ability to differentiate between tweets (and trolls) depending on the scale we wish to `zoom' in to. It might be the case that there are in fact two or more distinguishable sub-groups of news feed troll tweets, and that if we zoom in closely we are able to make sense of the microcosm of news feed troll tactics and activity. Likewise, at the aggregate scale we may wish to see where left troll tweets are positioned in relation to other types of tweets - are they grouped into a tight homogeneous cluster, or are the motives and actions of these trolls more heterogeneous due to their supporting role in the over-arching political goals of the IRA? Indeed, this is a primary goal of the framework we advance in this paper: balancing the ability to qualitatively explore and interpret social phenomena along with harnessing the power of computational techniques to analyse and visualise the data, as well as make accurate predictions.

% \todo[inline]{The following transition from the social theory to edit distance does not correctly reflect our approach. Note that we use edit distance to measure similarity between tweets (not between bots). 

% \begin{itemize}
% \item An identity of a bot can be revealed by sum of political ideologies of individual tweets consisting a trace of the bot. 
% \item A ideology of individual tweet can be identified by comparing against tweets with known ideologies. 
% \item The similarity between individual tweets can be modelled by their semantic distances (SED) and the temporal differences.
% \end{itemize}

% So far we have been focused on emphasising the importance of SED. However, I'd say SED is just a part of the overall framework now, and in order to emphasise the contribution from the social theory, we may emphasise the time-sensitive KNN (i just made up the name) which actually use the temporal distances between tweets.

% DW: Tim to rewrite this section.
% }

%In the case of Twitter data and identifying Russian troll accounts, it is easy to see that for a given `right troll' $u_i \in U$, their `monadic' identity can be described as a vector $\vec v$, which is a sequence of actions or events initiated by $u_i$, ordered by time. As a simplifying example, if we extract the hashtags that $u_i$ has used in tweets, we might find that they used \textit{\#MAGA} at time $t_0$, \textit{\#crookedhillary} at $t_1$, and \textit{\#clintonemails} at $t_2$. Thus the sequence $\vec v_i$ expressing their identity is $\left<\#MAGA, \#crookedhillary, \#clintonemails\right>$. Similarly, another right troll $u_j$ might have the following monadic identity $\vec v_j$: $\left<\#clintonemails, \#MAGA, \#trump2016\right>$, whilst a `left troll' $u_k$ authored the following sequence of hashtags $\vec v_k$: $\left<\#blacklivesmatter, \#bernieorbust, \#feelthebern\right>$. Although this example is purely illustrative, it is clear that the monadic identities of the right trolls, encoded as $\vec v_i$ and $\vec v_j$, are more similar compared to the left troll, encoded as $\vec v_k$. The question that we pose in this paper is whether we can exploit this approach to encoding identity in order to classify users based on similarities in their trace activity over time. In the next section we show how this is possible when we make some modifications to an approximate string matching technique known as edit distance.

%Edit distance has a wide range of applications, especially in information retrieval, natural language processing and computational biology \citep{navarro2001guided}. In terms of natural language processing, edit distance is applied to the correction of spelling mistakes or OCR (Optical Character Recognition) errors. \cite{arora2010recognition} combine neural networks and edit distance to recognize non-compound handwritten Devnagari characters and achieve a high recognition at 90.74\%. In OCR application, the edit distance is used to obtain the minimum number of the editing operations needed to transform the wrong word to the right word in the dictionary. In order to correct the wrong words, we reserve a set of solutions that require fewer editing operations. In computational biology, DNA and protein sequences can be seen as long strings over specific alphabets, which stores biological information representing the genetic code of living beings. It is fundamental and essential to search and comparing specific sequences over those strings. 
 
%Edit distance also has several limitations. In particular, it can only quantify the similarity of the structure of strings composed of symbols in an alphabet $\Sigma$, while not considering the semantic space in which the elements of $\Sigma$ occur. This is a limitation because while detecting social bots or trolls using edit distance, we want to take some contextual factors into account, in this case, the latent semantic structure of the input data (natural language expressed in tweets). For example, consider the following three sentences: ``I love music''; ``I hate music''; and ``I like music''. Every word can be considered as a symbol of some alphabet $\Sigma$, thus the edit distance between each pair of two sentences is 1. However, ``love'' is more semantically similar to ``like''. In this situation, the distance between ``I love music'' and ``I like music'' should be less than the distance between ``I love music'' and ``I hate music''. 

%It follows that if we wish to use edit distance to distinguish between the identity of Twitter users using unsupervised clustering techniques, then it is critical to take semantic similarity into account. This is the problem that we address in Section X. Before we tackle this problem, the next section provides details of the Russian Troll Dataset as well as the types of trolls that we aim to distinguish between using an unsupervised troll detection approach.